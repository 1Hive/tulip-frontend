{"ast":null,"code":"'use strict';\n\nconst multihashes = require('multihashes');\n\nconst CID = require('cids');\n\nconst protobuf = require('protons');\n\nconst fnv1a = require('fnv1a');\n\nconst varint = require('varint');\n\nconst {\n  DAGNode,\n  DAGLink\n} = require('ipld-dag-pb');\n\nconst multicodec = require('multicodec');\n\nconst {\n  default: Queue\n} = require('p-queue');\n\nconst dagCborLinks = require('dag-cbor-links');\n\nconst log = require('debug')('ipfs:pin:pin-set');\n\nconst pbSchema = require('./pin.proto');\n\nconst {\n  Buffer\n} = require('buffer');\n\nconst emptyKeyHash = 'QmdfTbBqBPQ7VNxZEYEj14VmRuZBkqFbiwReogJgS1zR1n';\nconst emptyKey = multihashes.fromB58String(emptyKeyHash);\nconst defaultFanout = 256;\nconst maxItems = 8192;\nconst pb = protobuf(pbSchema);\nconst HAS_DESCENDANT_CONCURRENCY = 100;\n\nfunction toB58String(hash) {\n  return new CID(hash).toBaseEncodedString();\n}\n\nfunction readHeader(rootNode) {\n  // rootNode.data should be a buffer of the format:\n  // < varint(headerLength) | header | itemData... >\n  const rootData = rootNode.Data;\n  const hdrLength = varint.decode(rootData);\n  const vBytes = varint.decode.bytes;\n\n  if (vBytes <= 0) {\n    throw new Error('Invalid Set header length');\n  }\n\n  if (vBytes + hdrLength > rootData.length) {\n    throw new Error('Impossibly large set header length');\n  }\n\n  const hdrSlice = rootData.slice(vBytes, hdrLength + vBytes);\n  const header = pb.Set.decode(hdrSlice);\n\n  if (header.version !== 1) {\n    throw new Error(`Unsupported Set version: ${header.version}`);\n  }\n\n  if (header.fanout > rootNode.Links.length) {\n    throw new Error('Impossibly large fanout');\n  }\n\n  return {\n    header: header,\n    data: rootData.slice(hdrLength + vBytes)\n  };\n}\n\nfunction hash(seed, key) {\n  const buf = Buffer.alloc(4);\n  buf.writeUInt32LE(seed, 0);\n  const data = Buffer.concat([buf, Buffer.from(toB58String(key))]);\n  return fnv1a(data.toString('binary'));\n}\n\nfunction* cborCids(node) {\n  for (const [_, cid] of dagCborLinks(node)) {\n    // eslint-disable-line no-unused-vars\n    yield cid;\n  }\n}\n\nexports = module.exports = function (dag) {\n  const pinSet = {\n    // should this be part of `object` API?\n    hasDescendant: async (parentCid, childhash) => {\n      if (parentCid.codec !== 'dag-pb' && parentCid.codec !== 'dag-cbor') {\n        return false;\n      }\n\n      const {\n        value: root\n      } = await dag.get(parentCid, {\n        preload: false\n      });\n      const queue = new Queue({\n        concurrency: HAS_DESCENDANT_CONCURRENCY\n      });\n\n      if (CID.isCID(childhash) || Buffer.isBuffer(childhash)) {\n        childhash = toB58String(childhash);\n      }\n\n      let found = false;\n      const seen = {};\n\n      function searchChild(linkCid) {\n        return async () => {\n          if (found) {\n            return;\n          }\n\n          try {\n            const {\n              value: childNode\n            } = await dag.get(linkCid, {\n              preload: false\n            });\n            searchChildren(linkCid, childNode);\n          } catch (err) {\n            log(err);\n          }\n        };\n      }\n\n      function searchChildren(cid, node) {\n        let links = [];\n\n        if (cid.codec === 'dag-pb') {\n          links = node.Links;\n        } else if (cid.codec === 'dag-cbor') {\n          links = cborCids(node);\n        }\n\n        for (const link of links) {\n          const linkCid = cid.codec === 'dag-pb' ? link.Hash : link[1];\n          const bs58Link = toB58String(linkCid);\n\n          if (bs58Link === childhash) {\n            queue.clear();\n            found = true;\n            return;\n          }\n\n          if (seen[bs58Link]) {\n            continue;\n          }\n\n          seen[bs58Link] = true;\n\n          if (linkCid.codec !== 'dag-pb' && linkCid.codec !== 'dag-cbor') {\n            continue;\n          }\n\n          queue.add(searchChild(linkCid));\n        }\n      }\n\n      searchChildren(parentCid, root);\n      await queue.onIdle();\n      return found;\n    },\n    storeSet: async keys => {\n      const pins = keys.map(key => {\n        if (typeof key === 'string' || Buffer.isBuffer(key)) {\n          key = new CID(key);\n        }\n\n        return {\n          key: key,\n          data: null\n        };\n      });\n      const rootNode = await pinSet.storeItems(pins);\n      const cid = await dag.put(rootNode, {\n        version: 0,\n        format: multicodec.DAG_PB,\n        hashAlg: multicodec.SHA2_256,\n        preload: false\n      });\n      return {\n        node: rootNode,\n        cid\n      };\n    },\n    storeItems: async items => {\n      // eslint-disable-line require-await\n      return storePins(items, 0);\n\n      async function storePins(pins, depth) {\n        const pbHeader = pb.Set.encode({\n          version: 1,\n          fanout: defaultFanout,\n          seed: depth\n        });\n        const headerBuf = Buffer.concat([Buffer.from(varint.encode(pbHeader.length)), pbHeader]);\n        const fanoutLinks = [];\n\n        for (let i = 0; i < defaultFanout; i++) {\n          fanoutLinks.push(new DAGLink('', 1, emptyKey));\n        }\n\n        if (pins.length <= maxItems) {\n          const nodes = pins.map(item => {\n            return {\n              link: new DAGLink('', 1, item.key),\n              data: item.data || Buffer.alloc(0)\n            };\n          }) // sorting makes any ordering of `pins` produce the same DAGNode\n          .sort((a, b) => Buffer.compare(a.link.Hash.buffer, b.link.Hash.buffer));\n          const rootLinks = fanoutLinks.concat(nodes.map(item => item.link));\n          const rootData = Buffer.concat([headerBuf].concat(nodes.map(item => item.data)));\n          return new DAGNode(rootData, rootLinks);\n        } else {\n          // If the array of pins is > maxItems, we:\n          //  - distribute the pins among `defaultFanout` bins\n          //    - create a DAGNode for each bin\n          //      - add each pin as a DAGLink to that bin\n          //  - create a root DAGNode\n          //    - add each bin as a DAGLink\n          //  - send that root DAGNode via callback\n          // (using go-ipfs' \"wasteful but simple\" approach for consistency)\n          // https://github.com/ipfs/go-ipfs/blob/master/pin/set.go#L57\n          const bins = pins.reduce((bins, pin) => {\n            const n = hash(depth, pin.key) % defaultFanout;\n            bins[n] = n in bins ? bins[n].concat([pin]) : [pin];\n            return bins;\n          }, []);\n          let idx = 0;\n\n          for (const bin of bins) {\n            const child = await storePins(bin, depth + 1);\n            await storeChild(child, idx);\n            idx++;\n          }\n\n          return new DAGNode(headerBuf, fanoutLinks);\n        }\n\n        async function storeChild(child, binIdx) {\n          const opts = {\n            version: 0,\n            format: multicodec.DAG_PB,\n            hashAlg: multicodec.SHA2_256,\n            preload: false\n          };\n          const cid = await dag.put(child, opts);\n          fanoutLinks[binIdx] = new DAGLink('', child.size, cid);\n        }\n      }\n    },\n    loadSet: async (rootNode, name) => {\n      const link = rootNode.Links.find(l => l.Name === name);\n\n      if (!link) {\n        throw new Error('No link found with name ' + name);\n      }\n\n      const res = await dag.get(link.Hash, '', {\n        preload: false\n      });\n      const keys = [];\n\n      const stepPin = link => keys.push(link.Hash);\n\n      await pinSet.walkItems(res.value, {\n        stepPin\n      });\n      return keys;\n    },\n    walkItems: async (node, {\n      stepPin = () => {},\n      stepBin = () => {}\n    }) => {\n      const pbh = readHeader(node);\n      let idx = 0;\n\n      for (const link of node.Links) {\n        if (idx < pbh.header.fanout) {\n          // the first pbh.header.fanout links are fanout bins\n          // if a fanout bin is not 'empty', dig into and walk its DAGLinks\n          const linkHash = link.Hash.buffer;\n\n          if (!emptyKey.equals(linkHash)) {\n            stepBin(link, idx, pbh.data); // walk the links of this fanout bin\n\n            const res = await dag.get(linkHash, '', {\n              preload: false\n            });\n            await pinSet.walkItems(res.value, {\n              stepPin,\n              stepBin\n            });\n          }\n        } else {\n          // otherwise, the link is a pin\n          stepPin(link, idx, pbh.data);\n        }\n\n        idx++;\n      }\n    },\n    getInternalCids: async rootNode => {\n      // \"Empty block\" used by the pinner\n      const cids = [new CID(emptyKey)];\n\n      const stepBin = link => cids.push(link.Hash);\n\n      for (const topLevelLink of rootNode.Links) {\n        cids.push(topLevelLink.Hash);\n        const res = await dag.get(topLevelLink.Hash, '', {\n          preload: false\n        });\n        await pinSet.walkItems(res.value, {\n          stepBin\n        });\n      }\n\n      return cids;\n    }\n  };\n  return pinSet;\n};","map":null,"metadata":{},"sourceType":"script"}