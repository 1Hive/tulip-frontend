{"ast":null,"code":"'use strict';\n\nvar _toConsumableArray = require(\"/Users/fabianmolina/Documents/1hive/tulip-frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/toConsumableArray\");\n\nvar _regeneratorRuntime = require(\"/Users/fabianmolina/Documents/1hive/tulip-frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\");\n\nvar _slicedToArray = require(\"/Users/fabianmolina/Documents/1hive/tulip-frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/slicedToArray\");\n\nvar _createForOfIteratorHelper = require(\"/Users/fabianmolina/Documents/1hive/tulip-frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/createForOfIteratorHelper\");\n\nvar _asyncToGenerator = require(\"/Users/fabianmolina/Documents/1hive/tulip-frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/asyncToGenerator\");\n\nvar _objectSpread = require(\"/Users/fabianmolina/Documents/1hive/tulip-frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/objectSpread2\");\n\nvar _classCallCheck = require(\"/Users/fabianmolina/Documents/1hive/tulip-frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/classCallCheck\");\n\nvar _createClass = require(\"/Users/fabianmolina/Documents/1hive/tulip-frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/createClass\");\n\nvar CID = require('cids');\n\nvar Message = require('../types/message');\n\nvar WantType = Message.WantType;\n\nvar Wantlist = require('../types/wantlist');\n\nvar Ledger = require('./ledger');\n\nvar RequestQueue = require('./req-queue');\n\nvar TaskMerger = require('./task-merger');\n\nvar _require = require('../utils'),\n    logger = _require.logger; // The ideal size of the batched payload. We try to pop this much data off the\n// request queue, but\n// - if there isn't any more data in the queue we send whatever we have\n// - if there are several small items in the queue (eg HAVE response) followed\n//   by one big item (eg a block) that would exceed this target size, we\n//   include the big item in the message\n\n\nvar TARGET_MESSAGE_SIZE = 16 * 1024; // If the client sends a want-have, and the engine has the corresponding block,\n// we check the size of the block and if it's small enough we send the block\n// itself, rather than sending a HAVE.\n// This constant defines the maximum size up to which we replace a HAVE with\n// a block.\n\nvar MAX_SIZE_REPLACE_HAS_WITH_BLOCK = 1024;\n\nvar DecisionEngine = /*#__PURE__*/function () {\n  function DecisionEngine(peerId, blockstore, network, stats, opts) {\n    _classCallCheck(this, DecisionEngine);\n\n    this._log = logger(peerId, 'engine');\n    this.blockstore = blockstore;\n    this.network = network;\n    this._stats = stats;\n    this._opts = this._processOpts(opts); // A list of of ledgers by their partner id\n\n    this.ledgerMap = new Map();\n    this._running = false; // Queue of want-have / want-block per peer\n\n    this._requestQueue = new RequestQueue(TaskMerger);\n  }\n\n  _createClass(DecisionEngine, [{\n    key: \"_processOpts\",\n    value: function _processOpts(opts) {\n      return _objectSpread({\n        maxSizeReplaceHasWithBlock: MAX_SIZE_REPLACE_HAS_WITH_BLOCK,\n        targetMessageSize: TARGET_MESSAGE_SIZE\n      }, opts);\n    }\n  }, {\n    key: \"_scheduleProcessTasks\",\n    value: function _scheduleProcessTasks() {\n      var _this = this;\n\n      setTimeout(function () {\n        _this._processTasks();\n      });\n    } // Pull tasks off the request queue and send a message to the corresponding\n    // peer\n\n  }, {\n    key: \"_processTasks\",\n    value: function () {\n      var _processTasks2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {\n        var _this$_requestQueue$p, peerId, tasks, pendingSize, msg, blockCids, blockTasks, _iterator, _step, task, cid, blocks, _iterator2, _step2, _step2$value, topic, taskData, blk, _cid, _iterator3, _step3, block;\n\n        return _regeneratorRuntime.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                if (this._running) {\n                  _context.next = 2;\n                  break;\n                }\n\n                return _context.abrupt(\"return\");\n\n              case 2:\n                _this$_requestQueue$p = this._requestQueue.popTasks(this._opts.targetMessageSize), peerId = _this$_requestQueue$p.peerId, tasks = _this$_requestQueue$p.tasks, pendingSize = _this$_requestQueue$p.pendingSize;\n\n                if (!(tasks.length === 0)) {\n                  _context.next = 5;\n                  break;\n                }\n\n                return _context.abrupt(\"return\");\n\n              case 5:\n                // Create a new message\n                msg = new Message(false); // Amount of data in the request queue still waiting to be popped\n\n                msg.setPendingBytes(pendingSize); // Split out want-blocks, want-haves and DONT_HAVEs\n\n                blockCids = [];\n                blockTasks = new Map();\n                _iterator = _createForOfIteratorHelper(tasks);\n\n                try {\n                  for (_iterator.s(); !(_step = _iterator.n()).done;) {\n                    task = _step.value;\n                    cid = new CID(task.topic);\n\n                    if (task.data.haveBlock) {\n                      if (task.data.isWantBlock) {\n                        blockCids.push(cid);\n                        blockTasks.set(task.topic, task.data);\n                      } else {\n                        // Add HAVES to the message\n                        msg.addHave(cid);\n                      }\n                    } else {\n                      // Add DONT_HAVEs to the message\n                      msg.addDontHave(cid);\n                    }\n                  }\n                } catch (err) {\n                  _iterator.e(err);\n                } finally {\n                  _iterator.f();\n                }\n\n                _context.next = 13;\n                return this._getBlocks(blockCids);\n\n              case 13:\n                blocks = _context.sent;\n                _iterator2 = _createForOfIteratorHelper(blockTasks);\n\n                try {\n                  for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {\n                    _step2$value = _slicedToArray(_step2.value, 2), topic = _step2$value[0], taskData = _step2$value[1];\n                    blk = blocks.get(topic); // If the block was found (it has not been removed)\n\n                    if (blk) {\n                      // Add the block to the message\n                      msg.addBlock(blk);\n                    } else {\n                      // The block was not found. If the client requested DONT_HAVE,\n                      // add DONT_HAVE to the message.\n                      if (taskData.sendDontHave) {\n                        _cid = new CID(topic);\n                        msg.addDontHave(_cid);\n                      }\n                    }\n                  } // If there's nothing in the message, bail out\n\n                } catch (err) {\n                  _iterator2.e(err);\n                } finally {\n                  _iterator2.f();\n                }\n\n                if (!msg.empty) {\n                  _context.next = 20;\n                  break;\n                }\n\n                this._requestQueue.tasksDone(peerId, tasks); // Trigger the next round of task processing\n\n\n                this._scheduleProcessTasks();\n\n                return _context.abrupt(\"return\");\n\n              case 20:\n                _context.prev = 20;\n                _context.next = 23;\n                return this.network.sendMessage(peerId, msg);\n\n              case 23:\n                // Peform sent message accounting\n                _iterator3 = _createForOfIteratorHelper(blocks.values());\n\n                try {\n                  for (_iterator3.s(); !(_step3 = _iterator3.n()).done;) {\n                    block = _step3.value;\n                    this.messageSent(peerId, block);\n                  }\n                } catch (err) {\n                  _iterator3.e(err);\n                } finally {\n                  _iterator3.f();\n                }\n\n                _context.next = 30;\n                break;\n\n              case 27:\n                _context.prev = 27;\n                _context.t0 = _context[\"catch\"](20);\n\n                this._log.error(_context.t0);\n\n              case 30:\n                // Free the tasks up from the request queue\n                this._requestQueue.tasksDone(peerId, tasks); // Trigger the next round of task processing\n\n\n                this._scheduleProcessTasks();\n\n              case 32:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, this, [[20, 27]]);\n      }));\n\n      function _processTasks() {\n        return _processTasks2.apply(this, arguments);\n      }\n\n      return _processTasks;\n    }()\n  }, {\n    key: \"wantlistForPeer\",\n    value: function wantlistForPeer(peerId) {\n      var peerIdStr = peerId.toB58String();\n\n      if (!this.ledgerMap.has(peerIdStr)) {\n        return new Map();\n      }\n\n      return this.ledgerMap.get(peerIdStr).wantlist.sortedEntries();\n    }\n  }, {\n    key: \"ledgerForPeer\",\n    value: function ledgerForPeer(peerId) {\n      var peerIdStr = peerId.toB58String();\n      var ledger = this.ledgerMap.get(peerIdStr);\n\n      if (!ledger) {\n        return null;\n      }\n\n      return {\n        peer: ledger.partner.toPrint(),\n        value: ledger.debtRatio(),\n        sent: ledger.accounting.bytesSent,\n        recv: ledger.accounting.bytesRecv,\n        exchanged: ledger.exchangeCount\n      };\n    }\n  }, {\n    key: \"peers\",\n    value: function peers() {\n      return Array.from(this.ledgerMap.values()).map(function (l) {\n        return l.partner;\n      });\n    } // Receive blocks either from an incoming message from the network, or from\n    // blocks being added by the client on the localhost (eg IPFS add)\n\n  }, {\n    key: \"receivedBlocks\",\n    value: function receivedBlocks(blocks) {\n      var _this2 = this;\n\n      if (!blocks.length) {\n        return;\n      } // For each connected peer, check if it wants the block we received\n\n\n      this.ledgerMap.forEach(function (ledger) {\n        blocks.forEach(function (block) {\n          // Filter out blocks that we don't want\n          var want = ledger.wantlistContains(block.cid);\n\n          if (!want) {\n            return;\n          } // If the block is small enough, just send the block, even if the\n          // client asked for a HAVE\n\n\n          var blockSize = block.data.length;\n\n          var isWantBlock = _this2._sendAsBlock(want.wantType, blockSize);\n\n          var entrySize = blockSize;\n\n          if (!isWantBlock) {\n            entrySize = Message.blockPresenceSize(want.cid);\n          }\n\n          _this2._requestQueue.pushTasks(ledger.partner, [{\n            topic: want.cid.toString(),\n            priority: want.priority,\n            size: entrySize,\n            data: {\n              blockSize: blockSize,\n              isWantBlock: isWantBlock,\n              haveBlock: true,\n              sendDontHave: false\n            }\n          }]);\n        });\n      });\n\n      this._scheduleProcessTasks();\n    } // Handle incoming messages\n\n  }, {\n    key: \"messageReceived\",\n    value: function () {\n      var _messageReceived = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2(peerId, msg) {\n        var ledger, cancels, wants;\n        return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n          while (1) {\n            switch (_context2.prev = _context2.next) {\n              case 0:\n                ledger = this._findOrCreate(peerId);\n\n                if (!msg.empty) {\n                  _context2.next = 3;\n                  break;\n                }\n\n                return _context2.abrupt(\"return\");\n\n              case 3:\n                // If the message has a full wantlist, clear the current wantlist\n                if (msg.full) {\n                  ledger.wantlist = new Wantlist();\n                } // Record the amount of block data received\n\n\n                this._updateBlockAccounting(msg.blocks, ledger);\n\n                if (!(msg.wantlist.size === 0)) {\n                  _context2.next = 8;\n                  break;\n                }\n\n                this._scheduleProcessTasks();\n\n                return _context2.abrupt(\"return\");\n\n              case 8:\n                // Clear cancelled wants and add new wants to the ledger\n                cancels = [];\n                wants = [];\n                msg.wantlist.forEach(function (entry) {\n                  if (entry.cancel) {\n                    ledger.cancelWant(entry.cid);\n                    cancels.push(entry.cid);\n                  } else {\n                    ledger.wants(entry.cid, entry.priority, entry.wantType);\n                    wants.push(entry);\n                  }\n                });\n\n                this._cancelWants(peerId, cancels);\n\n                _context2.next = 14;\n                return this._addWants(peerId, wants);\n\n              case 14:\n                this._scheduleProcessTasks();\n\n              case 15:\n              case \"end\":\n                return _context2.stop();\n            }\n          }\n        }, _callee2, this);\n      }));\n\n      function messageReceived(_x, _x2) {\n        return _messageReceived.apply(this, arguments);\n      }\n\n      return messageReceived;\n    }()\n  }, {\n    key: \"_cancelWants\",\n    value: function _cancelWants(peerId, cids) {\n      var _iterator4 = _createForOfIteratorHelper(cids),\n          _step4;\n\n      try {\n        for (_iterator4.s(); !(_step4 = _iterator4.n()).done;) {\n          var c = _step4.value;\n\n          this._requestQueue.remove(c.toString(), peerId);\n        }\n      } catch (err) {\n        _iterator4.e(err);\n      } finally {\n        _iterator4.f();\n      }\n    }\n  }, {\n    key: \"_addWants\",\n    value: function () {\n      var _addWants2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3(peerId, wants) {\n        var blockSizes, tasks, _iterator5, _step5, want, id, blockSize, isWantBlock, entrySize;\n\n        return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n          while (1) {\n            switch (_context3.prev = _context3.next) {\n              case 0:\n                _context3.next = 2;\n                return this._getBlockSizes(wants.map(function (w) {\n                  return w.cid;\n                }));\n\n              case 2:\n                blockSizes = _context3.sent;\n                tasks = [];\n                _iterator5 = _createForOfIteratorHelper(wants);\n\n                try {\n                  for (_iterator5.s(); !(_step5 = _iterator5.n()).done;) {\n                    want = _step5.value;\n                    id = want.cid.toString();\n                    blockSize = blockSizes.get(id); // If the block was not found\n\n                    if (blockSize == null) {\n                      // Only add the task to the queue if the requester wants a DONT_HAVE\n                      if (want.sendDontHave) {\n                        tasks.push({\n                          topic: id,\n                          priority: want.priority,\n                          size: Message.blockPresenceSize(want.cid),\n                          data: {\n                            isWantBlock: want.wantType === WantType.Block,\n                            blockSize: 0,\n                            haveBlock: false,\n                            sendDontHave: want.sendDontHave\n                          }\n                        });\n                      }\n                    } else {\n                      // The block was found, add it to the queue\n                      // If the block is small enough, just send the block, even if the\n                      // client asked for a HAVE\n                      isWantBlock = this._sendAsBlock(want.wantType, blockSize); // entrySize is the amount of space the entry takes up in the\n                      // message we send to the recipient. If we're sending a block, the\n                      // entrySize is the size of the block. Otherwise it's the size of\n                      // a block presence entry.\n\n                      entrySize = blockSize;\n\n                      if (!isWantBlock) {\n                        entrySize = Message.blockPresenceSize(want.cid);\n                      }\n\n                      tasks.push({\n                        topic: id,\n                        priority: want.priority,\n                        size: entrySize,\n                        data: {\n                          isWantBlock: isWantBlock,\n                          blockSize: blockSize,\n                          haveBlock: true,\n                          sendDontHave: want.sendDontHave\n                        }\n                      });\n                    }\n\n                    this._requestQueue.pushTasks(peerId, tasks);\n                  }\n                } catch (err) {\n                  _iterator5.e(err);\n                } finally {\n                  _iterator5.f();\n                }\n\n              case 6:\n              case \"end\":\n                return _context3.stop();\n            }\n          }\n        }, _callee3, this);\n      }));\n\n      function _addWants(_x3, _x4) {\n        return _addWants2.apply(this, arguments);\n      }\n\n      return _addWants;\n    }()\n  }, {\n    key: \"_sendAsBlock\",\n    value: function _sendAsBlock(wantType, blockSize) {\n      return wantType === WantType.Block || blockSize <= this._opts.maxSizeReplaceHasWithBlock;\n    }\n  }, {\n    key: \"_getBlockSizes\",\n    value: function () {\n      var _getBlockSizes2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee4(cids) {\n        var blocks;\n        return _regeneratorRuntime.wrap(function _callee4$(_context4) {\n          while (1) {\n            switch (_context4.prev = _context4.next) {\n              case 0:\n                _context4.next = 2;\n                return this._getBlocks(cids);\n\n              case 2:\n                blocks = _context4.sent;\n                return _context4.abrupt(\"return\", new Map(_toConsumableArray(blocks).map(function (_ref) {\n                  var _ref2 = _slicedToArray(_ref, 2),\n                      k = _ref2[0],\n                      v = _ref2[1];\n\n                  return [k, v.data.length];\n                })));\n\n              case 4:\n              case \"end\":\n                return _context4.stop();\n            }\n          }\n        }, _callee4, this);\n      }));\n\n      function _getBlockSizes(_x5) {\n        return _getBlockSizes2.apply(this, arguments);\n      }\n\n      return _getBlockSizes;\n    }()\n  }, {\n    key: \"_getBlocks\",\n    value: function () {\n      var _getBlocks2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee6(cids) {\n        var _this3 = this;\n\n        var res;\n        return _regeneratorRuntime.wrap(function _callee6$(_context6) {\n          while (1) {\n            switch (_context6.prev = _context6.next) {\n              case 0:\n                res = new Map();\n                _context6.next = 3;\n                return Promise.all(cids.map( /*#__PURE__*/function () {\n                  var _ref3 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee5(cid) {\n                    var block;\n                    return _regeneratorRuntime.wrap(function _callee5$(_context5) {\n                      while (1) {\n                        switch (_context5.prev = _context5.next) {\n                          case 0:\n                            _context5.prev = 0;\n                            _context5.next = 3;\n                            return _this3.blockstore.get(cid);\n\n                          case 3:\n                            block = _context5.sent;\n                            res.set(cid.toString(), block);\n                            _context5.next = 10;\n                            break;\n\n                          case 7:\n                            _context5.prev = 7;\n                            _context5.t0 = _context5[\"catch\"](0);\n\n                            if (_context5.t0.code !== 'ERR_NOT_FOUND') {\n                              _this3._log.error('failed to query blockstore for %s: %s', cid, _context5.t0);\n                            }\n\n                          case 10:\n                          case \"end\":\n                            return _context5.stop();\n                        }\n                      }\n                    }, _callee5, null, [[0, 7]]);\n                  }));\n\n                  return function (_x7) {\n                    return _ref3.apply(this, arguments);\n                  };\n                }()));\n\n              case 3:\n                return _context6.abrupt(\"return\", res);\n\n              case 4:\n              case \"end\":\n                return _context6.stop();\n            }\n          }\n        }, _callee6);\n      }));\n\n      function _getBlocks(_x6) {\n        return _getBlocks2.apply(this, arguments);\n      }\n\n      return _getBlocks;\n    }()\n  }, {\n    key: \"_updateBlockAccounting\",\n    value: function _updateBlockAccounting(blocksMap, ledger) {\n      var _this4 = this;\n\n      blocksMap.forEach(function (b) {\n        _this4._log('got block (%s bytes)', b.data.length);\n\n        ledger.receivedBytes(b.data.length);\n      });\n    } // Clear up all accounting things after message was sent\n\n  }, {\n    key: \"messageSent\",\n    value: function messageSent(peerId, block) {\n      var ledger = this._findOrCreate(peerId);\n\n      ledger.sentBytes(block ? block.data.length : 0);\n\n      if (block && block.cid) {\n        ledger.wantlist.remove(block.cid);\n      }\n    }\n  }, {\n    key: \"numBytesSentTo\",\n    value: function numBytesSentTo(peerId) {\n      return this._findOrCreate(peerId).accounting.bytesSent;\n    }\n  }, {\n    key: \"numBytesReceivedFrom\",\n    value: function numBytesReceivedFrom(peerId) {\n      return this._findOrCreate(peerId).accounting.bytesRecv;\n    }\n  }, {\n    key: \"peerDisconnected\",\n    value: function peerDisconnected(peerId) {// if (this.ledgerMap.has(peerId.toB58String())) {\n      //   this.ledgerMap.delete(peerId.toB58String())\n      // }\n      //\n      // TODO: figure out how to remove all other references\n      // in the peer request queue\n    }\n  }, {\n    key: \"_findOrCreate\",\n    value: function _findOrCreate(peerId) {\n      var peerIdStr = peerId.toB58String();\n\n      if (this.ledgerMap.has(peerIdStr)) {\n        return this.ledgerMap.get(peerIdStr);\n      }\n\n      var l = new Ledger(peerId);\n      this.ledgerMap.set(peerIdStr, l);\n\n      if (this._stats) {\n        this._stats.push(peerIdStr, 'peerCount', 1);\n      }\n\n      return l;\n    }\n  }, {\n    key: \"start\",\n    value: function start() {\n      this._running = true;\n    }\n  }, {\n    key: \"stop\",\n    value: function stop() {\n      this._running = false;\n    }\n  }]);\n\n  return DecisionEngine;\n}();\n\nmodule.exports = DecisionEngine;","map":null,"metadata":{},"sourceType":"script"}