{"ast":null,"code":"'use strict';\n\nvar _regeneratorRuntime = require(\"/Users/fabianmolina/Documents/1hive/tulip-frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\");\n\nvar _asyncToGenerator = require(\"/Users/fabianmolina/Documents/1hive/tulip-frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/asyncToGenerator\");\n\nvar _classCallCheck = require(\"/Users/fabianmolina/Documents/1hive/tulip-frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/classCallCheck\");\n\nvar _createClass = require(\"/Users/fabianmolina/Documents/1hive/tulip-frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/createClass\");\n\nvar queue = require('async/queue');\n\nvar promiseToCallback = require('promise-to-callback');\n\nvar WorkerQueue = /*#__PURE__*/function () {\n  /**\n   * Creates a new WorkerQueue.\n   *\n   * @param {DHT} dht\n   * @param {Run} run\n   * @param {Object} path\n   * @param {function} log\n   */\n  function WorkerQueue(dht, run, path, log) {\n    _classCallCheck(this, WorkerQueue);\n\n    this.dht = dht;\n    this.run = run;\n    this.path = path;\n    this.log = log;\n    this.concurrency = this.dht.concurrency;\n    this.queue = this.setupQueue(); // a container for resolve/reject functions that will be populated\n    // when execute() is called\n\n    this.execution = null;\n  }\n  /**\n   * Create the underlying async queue.\n   *\n   * @returns {Object}\n   */\n\n\n  _createClass(WorkerQueue, [{\n    key: \"setupQueue\",\n    value: function setupQueue() {\n      var _this = this;\n\n      var q = queue(function (peer, cb) {\n        promiseToCallback(_this.processNext(peer))(cb);\n      }, this.concurrency); // If there's an error, stop the worker\n\n      q.error = function (err) {\n        _this.log.error('queue', err);\n\n        _this.stop(err);\n      }; // When all peers in the queue have been processed, stop the worker\n\n\n      q.drain = function () {\n        _this.log('queue:drain');\n\n        _this.stop();\n      }; // When a space opens up in the queue, add some more peers\n\n\n      q.unsaturated = function () {\n        if (_this.running) {\n          _this.fill();\n        }\n      };\n\n      q.buffer = 0;\n      return q;\n    }\n    /**\n     * Stop the worker, optionally providing an error to pass to the worker's\n     * callback.\n     *\n     * @param {Error} err\n     */\n\n  }, {\n    key: \"stop\",\n    value: function stop(err) {\n      if (!this.running) {\n        return;\n      }\n\n      this.running = false;\n      this.queue.kill();\n      this.log('worker:stop, %d workers still running', this.run.workers.filter(function (w) {\n        return w.running;\n      }).length);\n\n      if (err) {\n        this.execution.reject(err);\n      } else {\n        this.execution.resolve();\n      }\n    }\n    /**\n     * Use the queue from async to keep `concurrency` amount items running\n     * per path.\n     *\n     * @return {Promise<void>}\n     */\n\n  }, {\n    key: \"execute\",\n    value: function () {\n      var _execute = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {\n        var _this2 = this;\n\n        var execPromise;\n        return _regeneratorRuntime.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                this.running = true; // store the promise resolution functions to be resolved at end of queue\n\n                this.execution = {};\n                execPromise = new Promise(function (resolve, reject) {\n                  return Object.assign(_this2.execution, {\n                    resolve: resolve,\n                    reject: reject\n                  });\n                }); // start queue\n\n                this.fill(); // await completion\n\n                _context.next = 6;\n                return execPromise;\n\n              case 6:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, this);\n      }));\n\n      function execute() {\n        return _execute.apply(this, arguments);\n      }\n\n      return execute;\n    }()\n    /**\n     * Add peers to the worker queue until there are enough to satisfy the\n     * worker queue concurrency.\n     * Note that we don't want to take any more than those required to satisfy\n     * concurrency from the peers-to-query queue, because we always want to\n     * query the closest peers to the key first, and new peers are continously\n     * being added to the peers-to-query queue.\n     */\n\n  }, {\n    key: \"fill\",\n    value: function fill() {\n      // Note:\n      // - queue.running(): number of items that are currently running\n      // - queue.length(): the number of items that are waiting to be run\n      while (this.queue.running() + this.queue.length() < this.concurrency && this.path.peersToQuery.length > 0) {\n        this.queue.push(this.path.peersToQuery.dequeue());\n      }\n    }\n    /**\n     * Process the next peer in the queue\n     *\n     * @param {PeerId} peer\n     * @returns {Promise<void>}\n     */\n\n  }, {\n    key: \"processNext\",\n    value: function () {\n      var _processNext = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2(peer) {\n        var continueQuerying, continueQueryingError, state, execError;\n        return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n          while (1) {\n            switch (_context2.prev = _context2.next) {\n              case 0:\n                if (this.running) {\n                  _context2.next = 2;\n                  break;\n                }\n\n                return _context2.abrupt(\"return\");\n\n              case 2:\n                if (!this.run.peersSeen.has(peer.toB58String())) {\n                  _context2.next = 4;\n                  break;\n                }\n\n                return _context2.abrupt(\"return\");\n\n              case 4:\n                _context2.prev = 4;\n                _context2.next = 7;\n                return this.run.continueQuerying(this);\n\n              case 7:\n                continueQuerying = _context2.sent;\n                _context2.next = 13;\n                break;\n\n              case 10:\n                _context2.prev = 10;\n                _context2.t0 = _context2[\"catch\"](4);\n                continueQueryingError = _context2.t0;\n\n              case 13:\n                if (this.running) {\n                  _context2.next = 15;\n                  break;\n                }\n\n                return _context2.abrupt(\"return\");\n\n              case 15:\n                if (!continueQueryingError) {\n                  _context2.next = 17;\n                  break;\n                }\n\n                throw continueQueryingError;\n\n              case 17:\n                if (continueQuerying) {\n                  _context2.next = 20;\n                  break;\n                }\n\n                this.stop();\n                return _context2.abrupt(\"return\");\n\n              case 20:\n                if (!this.run.peersSeen.has(peer.toB58String())) {\n                  _context2.next = 22;\n                  break;\n                }\n\n                return _context2.abrupt(\"return\");\n\n              case 22:\n                this.run.peersSeen.add(peer.toB58String()); // Execute the query on the next peer\n\n                this.log('queue:work');\n                _context2.prev = 24;\n                _context2.next = 27;\n                return this.execQuery(peer);\n\n              case 27:\n                state = _context2.sent;\n                _context2.next = 33;\n                break;\n\n              case 30:\n                _context2.prev = 30;\n                _context2.t1 = _context2[\"catch\"](24);\n                execError = _context2.t1;\n\n              case 33:\n                if (this.running) {\n                  _context2.next = 35;\n                  break;\n                }\n\n                return _context2.abrupt(\"return\");\n\n              case 35:\n                this.log('queue:work:done', execError, state);\n\n                if (!execError) {\n                  _context2.next = 38;\n                  break;\n                }\n\n                throw execError;\n\n              case 38:\n                if (!(state && state.queryComplete)) {\n                  _context2.next = 42;\n                  break;\n                }\n\n                this.log('query:complete');\n                this.run.stop();\n                return _context2.abrupt(\"return\");\n\n              case 42:\n                // If path is complete, just stop this worker.\n                // Note: this.stop() kills the queue and resolves execution\n                if (state && state.pathComplete) {\n                  this.stop();\n                }\n\n              case 43:\n              case \"end\":\n                return _context2.stop();\n            }\n          }\n        }, _callee2, this, [[4, 10], [24, 30]]);\n      }));\n\n      function processNext(_x) {\n        return _processNext.apply(this, arguments);\n      }\n\n      return processNext;\n    }()\n    /**\n     * Execute a query on the next peer.\n     *\n     * @param {PeerId} peer\n     * @returns {Promise<void>}\n     * @private\n     */\n\n  }, {\n    key: \"execQuery\",\n    value: function () {\n      var _execQuery = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee4(peer) {\n        var _this3 = this;\n\n        var res, queryError;\n        return _regeneratorRuntime.wrap(function _callee4$(_context4) {\n          while (1) {\n            switch (_context4.prev = _context4.next) {\n              case 0:\n                _context4.prev = 0;\n                _context4.next = 3;\n                return this.path.queryFunc(peer);\n\n              case 3:\n                res = _context4.sent;\n                _context4.next = 9;\n                break;\n\n              case 6:\n                _context4.prev = 6;\n                _context4.t0 = _context4[\"catch\"](0);\n                queryError = _context4.t0;\n\n              case 9:\n                if (this.running) {\n                  _context4.next = 11;\n                  break;\n                }\n\n                return _context4.abrupt(\"return\");\n\n              case 11:\n                if (!queryError) {\n                  _context4.next = 14;\n                  break;\n                }\n\n                this.run.errors.push(queryError);\n                return _context4.abrupt(\"return\");\n\n              case 14:\n                _context4.next = 16;\n                return this.run.peersQueried.add(peer);\n\n              case 16:\n                if (!(res.pathComplete || res.queryComplete)) {\n                  _context4.next = 19;\n                  break;\n                }\n\n                this.path.res = res;\n                return _context4.abrupt(\"return\", {\n                  pathComplete: res.pathComplete,\n                  queryComplete: res.queryComplete\n                });\n\n              case 19:\n                if (!(res.closerPeers && res.closerPeers.length > 0)) {\n                  _context4.next = 22;\n                  break;\n                }\n\n                _context4.next = 22;\n                return Promise.all(res.closerPeers.map( /*#__PURE__*/function () {\n                  var _ref = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3(closer) {\n                    return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n                      while (1) {\n                        switch (_context3.prev = _context3.next) {\n                          case 0:\n                            if (!_this3.dht._isSelf(closer.id)) {\n                              _context3.next = 2;\n                              break;\n                            }\n\n                            return _context3.abrupt(\"return\");\n\n                          case 2:\n                            closer = _this3.dht.peerStore.put(closer);\n\n                            _this3.dht._peerDiscovered(closer);\n\n                            _context3.next = 6;\n                            return _this3.path.addPeerToQuery(closer.id);\n\n                          case 6:\n                          case \"end\":\n                            return _context3.stop();\n                        }\n                      }\n                    }, _callee3);\n                  }));\n\n                  return function (_x3) {\n                    return _ref.apply(this, arguments);\n                  };\n                }()));\n\n              case 22:\n              case \"end\":\n                return _context4.stop();\n            }\n          }\n        }, _callee4, this, [[0, 6]]);\n      }));\n\n      function execQuery(_x2) {\n        return _execQuery.apply(this, arguments);\n      }\n\n      return execQuery;\n    }()\n  }]);\n\n  return WorkerQueue;\n}();\n\nmodule.exports = WorkerQueue;","map":null,"metadata":{},"sourceType":"script"}