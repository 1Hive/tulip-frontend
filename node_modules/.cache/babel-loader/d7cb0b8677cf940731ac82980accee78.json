{"ast":null,"code":"'use strict';\n\nconst log = require('debug')('ipfs:mfs:write');\n\nconst importer = require('ipfs-unixfs-importer');\n\nconst {\n  Buffer\n} = require('buffer');\n\nconst stat = require('./stat');\n\nconst mkdir = require('./mkdir');\n\nconst addLink = require('./utils/add-link');\n\nconst applyDefaultOptions = require('./utils/apply-default-options');\n\nconst createLock = require('./utils/create-lock');\n\nconst toAsyncIterator = require('./utils/to-async-iterator');\n\nconst toMfsPath = require('./utils/to-mfs-path');\n\nconst toPathComponents = require('./utils/to-path-components');\n\nconst toTrail = require('./utils/to-trail');\n\nconst updateTree = require('./utils/update-tree');\n\nconst updateMfsRoot = require('./utils/update-mfs-root');\n\nconst errCode = require('err-code');\n\nconst {\n  MFS_MAX_CHUNK_SIZE\n} = require('../../utils');\n\nconst last = require('it-last');\n\nconst {\n  withTimeoutOption\n} = require('../../utils');\n\nconst defaultOptions = {\n  offset: 0,\n  // the offset in the file to begin writing\n  length: undefined,\n  // how many bytes from the incoming buffer to write\n  create: false,\n  // whether to create the file if it does not exist\n  truncate: false,\n  // whether to truncate the file first\n  rawLeaves: false,\n  reduceSingleLeafToSelf: false,\n  cidVersion: 0,\n  hashAlg: 'sha2-256',\n  parents: false,\n  // whether to create intermediate directories if they do not exist\n  progress: () => {},\n  strategy: 'trickle',\n  flush: true,\n  leafType: 'raw',\n  shardSplitThreshold: 1000,\n  mode: undefined,\n  mtime: undefined\n};\n\nmodule.exports = context => {\n  return withTimeoutOption(async function mfsWrite(path, content, options) {\n    options = applyDefaultOptions(options, defaultOptions);\n    let source, destination, parent;\n    log('Reading source, destination and parent');\n    await createLock().readLock(async () => {\n      source = await toAsyncIterator(content, options);\n      destination = await toMfsPath(context, path);\n      parent = await toMfsPath(context, destination.mfsDirectory);\n    })();\n    log('Read source, destination and parent');\n\n    if (!options.parents && !parent.exists) {\n      throw errCode(new Error('directory does not exist'), 'ERR_NO_EXIST');\n    }\n\n    if (!options.create && !destination.exists) {\n      throw errCode(new Error('file does not exist'), 'ERR_NO_EXIST');\n    }\n\n    return updateOrImport(context, path, source, destination, options);\n  });\n};\n\nconst updateOrImport = async (context, path, source, destination, options) => {\n  const child = await write(context, source, destination, options); // The slow bit is done, now add or replace the DAGLink in the containing directory\n  // re-reading the path to the containing folder in case it has changed in the interim\n\n  await createLock().writeLock(async () => {\n    const pathComponents = toPathComponents(path);\n    const fileName = pathComponents.pop();\n    let parentExists = false;\n\n    try {\n      await stat(context)(`/${pathComponents.join('/')}`, options);\n      parentExists = true;\n    } catch (err) {\n      if (err.code !== 'ERR_NOT_FOUND') {\n        throw err;\n      }\n    }\n\n    if (!parentExists) {\n      await mkdir(context)(`/${pathComponents.join('/')}`, options);\n    } // get an updated mfs path in case the root changed while we were writing\n\n\n    const updatedPath = await toMfsPath(context, path);\n    const trail = await toTrail(context, updatedPath.mfsDirectory, options);\n    const parent = trail[trail.length - 1];\n\n    if (!parent.type.includes('directory')) {\n      throw errCode(new Error(`cannot write to ${parent.name}: Not a directory`), 'ERR_NOT_A_DIRECTORY');\n    }\n\n    const parentNode = await context.ipld.get(parent.cid);\n    const result = await addLink(context, {\n      parent: parentNode,\n      name: fileName,\n      cid: child.cid,\n      size: child.size,\n      flush: options.flush,\n      shardSplitThreshold: options.shardSplitThreshold,\n      hashAlg: options.hashAlg,\n      cidVersion: options.cidVersion\n    });\n    parent.cid = result.cid; // update the tree with the new child\n\n    const newRootCid = await updateTree(context, trail, options); // Update the MFS record with the new CID for the root of the tree\n\n    await updateMfsRoot(context, newRootCid);\n  })();\n};\n\nconst write = async (context, source, destination, options) => {\n  if (destination.exists) {\n    log(`Overwriting file ${destination.cid} offset ${options.offset} length ${options.length}`);\n  } else {\n    log(`Writing file offset ${options.offset} length ${options.length}`);\n  }\n\n  const sources = []; // pad start of file if necessary\n\n  if (options.offset > 0) {\n    if (destination.unixfs) {\n      log(`Writing first ${options.offset} bytes of original file`);\n      sources.push(() => {\n        return destination.content({\n          offset: 0,\n          length: options.offset\n        });\n      });\n\n      if (destination.unixfs.fileSize() < options.offset) {\n        const extra = options.offset - destination.unixfs.fileSize();\n        log(`Writing zeros for extra ${extra} bytes`);\n        sources.push(asyncZeroes(extra));\n      }\n    } else {\n      log(`Writing zeros for first ${options.offset} bytes`);\n      sources.push(asyncZeroes(options.offset));\n    }\n  }\n\n  sources.push(limitAsyncStreamBytes(source, options.length));\n  const content = countBytesStreamed(catAsyncIterators(sources), bytesWritten => {\n    if (destination.unixfs && !options.truncate) {\n      // if we've done reading from the new source and we are not going\n      // to truncate the file, add the end of the existing file to the output\n      const fileSize = destination.unixfs.fileSize();\n\n      if (fileSize > bytesWritten) {\n        log(`Writing last ${fileSize - bytesWritten} of ${fileSize} bytes from original file starting at offset ${bytesWritten}`);\n        return destination.content({\n          offset: bytesWritten\n        });\n      } else {\n        log('Not writing last bytes from original file');\n      }\n    }\n\n    return {\n      [Symbol.asyncIterator]: async function* () {}\n    };\n  });\n  let mode;\n\n  if (options.mode !== undefined && options.mode !== null) {\n    mode = options.mode;\n  } else if (destination && destination.unixfs) {\n    mode = destination.unixfs.mode;\n  }\n\n  let mtime;\n\n  if (options.mtime !== undefined && options.mtine !== null) {\n    mtime = options.mtime;\n  } else if (destination && destination.unixfs) {\n    mtime = destination.unixfs.mtime;\n  }\n\n  const result = await last(importer([{\n    content: content,\n    // persist mode & mtime if set previously\n    mode,\n    mtime\n  }], context.block, {\n    progress: options.progress,\n    hashAlg: options.hashAlg,\n    cidVersion: options.cidVersion,\n    strategy: options.strategy,\n    rawLeaves: options.rawLeaves,\n    reduceSingleLeafToSelf: options.reduceSingleLeafToSelf,\n    leafType: options.leafType,\n    pin: false\n  }));\n  log(`Wrote ${result.cid}`);\n  return {\n    cid: result.cid,\n    size: result.size\n  };\n};\n\nconst limitAsyncStreamBytes = (stream, limit) => {\n  return async function* _limitAsyncStreamBytes() {\n    let emitted = 0;\n\n    for await (const buf of stream) {\n      emitted += buf.length;\n\n      if (emitted > limit) {\n        yield buf.slice(0, limit - emitted);\n        return;\n      }\n\n      yield buf;\n    }\n  };\n};\n\nconst asyncZeroes = (count, chunkSize = MFS_MAX_CHUNK_SIZE) => {\n  const buf = Buffer.alloc(chunkSize, 0);\n  const stream = {\n    [Symbol.asyncIterator]: function* _asyncZeroes() {\n      while (true) {\n        yield buf.slice();\n      }\n    }\n  };\n  return limitAsyncStreamBytes(stream, count);\n};\n\nconst catAsyncIterators = async function* (sources) {\n  // eslint-disable-line require-await\n  for (let i = 0; i < sources.length; i++) {\n    yield* sources[i]();\n  }\n};\n\nconst countBytesStreamed = async function* (source, notify) {\n  let wrote = 0;\n\n  for await (const buf of source) {\n    wrote += buf.length;\n    yield buf;\n  }\n\n  for await (const buf of notify(wrote)) {\n    wrote += buf.length;\n    yield buf;\n  }\n};","map":null,"metadata":{},"sourceType":"script"}