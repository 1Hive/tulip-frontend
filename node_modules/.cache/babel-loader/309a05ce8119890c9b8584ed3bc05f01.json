{"ast":null,"code":"const EventEmitter = require('events').EventEmitter;\n\nconst pMap = require('p-map');\n\nconst Log = require('ipfs-log');\n\nconst Logger = require('logplease');\n\nconst logger = Logger.create('replicator', {\n  color: Logger.Colors.Cyan\n});\nLogger.setLogLevel('ERROR');\n\nconst getNext = e => e.next;\n\nconst flatMap = (res, val) => res.concat(val);\n\nconst notNull = entry => entry !== null && entry !== undefined;\n\nconst uniqueValues = (res, val) => {\n  res[val] = val;\n  return res;\n};\n\nconst batchSize = 1;\n\nclass Replicator extends EventEmitter {\n  constructor(store, concurrency) {\n    super();\n    this._store = store;\n    this._fetching = {};\n    this._stats = {\n      tasksRequested: 0,\n      tasksStarted: 0,\n      tasksProcessed: 0\n    };\n    this._buffer = [];\n    this._concurrency = concurrency || 128;\n    this._queue = {};\n    this._q = new Set(); // Flush the queue as an emergency switch\n\n    this._flushTimer = setInterval(() => {\n      if (this.tasksRunning === 0 && Object.keys(this._queue).length > 0) {\n        logger.warn('Had to flush the queue!', Object.keys(this._queue).length, 'items in the queue, ', this.tasksRequested, this.tasksFinished, ' tasks requested/finished');\n        setTimeout(() => this._processQueue(), 0);\n      }\n    }, 3000);\n  }\n  /**\n   * Returns the number of tasks started during the life time\n   * @return {[Integer]} [Number of tasks started]\n   */\n\n\n  get tasksRequested() {\n    return this._stats.tasksRequested;\n  }\n  /**\n   * Returns the number of tasks started during the life time\n   * @return {[Integer]} [Number of tasks running]\n   */\n\n\n  get tasksStarted() {\n    return this._stats.tasksStarted;\n  }\n  /**\n   * Returns the number of tasks running currently\n   * @return {[Integer]} [Number of tasks running]\n   */\n\n\n  get tasksRunning() {\n    return this._stats.tasksStarted - this._stats.tasksProcessed;\n  }\n  /**\n   * Returns the number of tasks currently queued\n   * @return {[Integer]} [Number of tasks queued]\n   */\n\n\n  get tasksQueued() {\n    return Math.max(Object.keys(this._queue).length - this.tasksRunning, 0);\n  }\n  /**\n   * Returns the number of tasks finished during the life time\n   * @return {[Integer]} [Number of tasks finished]\n   */\n\n\n  get tasksFinished() {\n    return this._stats.tasksProcessed;\n  }\n  /**\n   * Returns the hashes currently queued\n   * @return {[Array<String>]} [Queued hashes]\n   */\n\n\n  getQueue() {\n    return Object.values(this._queue);\n  }\n  /*\n    Process new heads.\n   */\n\n\n  load(entries) {\n    const notKnown = entry => {\n      const hash = entry.hash || entry;\n      return !this._store._oplog.has(hash) && !this._fetching[hash] && !this._queue[hash];\n    };\n\n    try {\n      entries.filter(notNull).filter(notKnown).forEach(this._addToQueue.bind(this));\n      setTimeout(() => this._processQueue(), 0);\n    } catch (e) {\n      console.error(e);\n    }\n  }\n\n  stop() {\n    // Clears the queue flusher\n    clearInterval(this._flushTimer); // Remove event listeners\n\n    this.removeAllListeners('load.added');\n    this.removeAllListeners('load.end');\n    this.removeAllListeners('load.progress');\n  }\n\n  _addToQueue(entry) {\n    const hash = entry.hash || entry;\n    this._stats.tasksRequested += 1;\n    this._queue[hash] = entry;\n  }\n\n  async _processQueue() {\n    if (this.tasksRunning < this._concurrency) {\n      const capacity = this._concurrency - this.tasksRunning;\n      const items = Object.values(this._queue).slice(0, capacity).filter(notNull);\n      items.forEach(entry => delete this._queue[entry.hash || entry]);\n\n      const flattenAndGetUniques = nexts => nexts.reduce(flatMap, []).reduce(uniqueValues, {});\n\n      const processValues = nexts => {\n        const values = Object.values(nexts).filter(notNull);\n\n        if (items.length > 0 && this._buffer.length > 0 || this.tasksRunning === 0 && this._buffer.length > 0) {\n          const logs = this._buffer.slice();\n\n          this._buffer = [];\n          this.emit('load.end', logs);\n        }\n\n        if (values.length > 0) {\n          this.load(values);\n        }\n      };\n\n      return pMap(items, e => this._processOne(e)).then(flattenAndGetUniques).then(processValues);\n    }\n  }\n\n  async _processOne(entry) {\n    const hash = entry.hash || entry;\n\n    if (this._store._oplog.has(hash) || this._fetching[hash]) {\n      return;\n    }\n\n    this._fetching[hash] = hash;\n    this.emit('load.added', entry);\n    this._stats.tasksStarted += 1;\n    const exclude = [];\n    const log = await Log.fromEntryHash(this._store._ipfs, this._store.identity, hash, {\n      logId: this._store._oplog.id,\n      access: this._store.access,\n      length: batchSize,\n      exclude\n    });\n\n    this._buffer.push(log);\n\n    const latest = log.values[0];\n    delete this._queue[hash]; // Mark this task as processed\n\n    this._stats.tasksProcessed += 1; // Notify subscribers that we made progress\n\n    this.emit('load.progress', this._id, hash, latest, null, this._buffer.length); // Return all next pointers\n\n    return log.values.map(getNext).reduce(flatMap, []);\n  }\n\n}\n\nmodule.exports = Replicator;","map":null,"metadata":{},"sourceType":"script"}