{"ast":null,"code":"'use strict';\n\nvar _regeneratorRuntime = require(\"/Users/fabianmolina/Documents/1hive/tulip-frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\");\n\nvar _objectSpread = require(\"/Users/fabianmolina/Documents/1hive/tulip-frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/objectSpread2\");\n\nvar _asyncToGenerator = require(\"/Users/fabianmolina/Documents/1hive/tulip-frontend/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/asyncToGenerator\");\n\nvar _require = require('ipld-dag-pb'),\n    DAGLink = _require.DAGLink,\n    DAGNode = _require.DAGNode;\n\nvar CID = require('cids');\n\nvar log = require('debug')('ipfs:mfs:core:utils:add-link');\n\nvar UnixFS = require('ipfs-unixfs');\n\nvar DirSharded = require('ipfs-unixfs-importer/src/dir-sharded');\n\nvar _require2 = require('./hamt-utils'),\n    updateHamtDirectory = _require2.updateHamtDirectory,\n    recreateHamtLevel = _require2.recreateHamtLevel,\n    createShard = _require2.createShard,\n    toPrefix = _require2.toPrefix,\n    addLinksToHamtBucket = _require2.addLinksToHamtBucket;\n\nvar errCode = require('err-code');\n\nvar mc = require('multicodec');\n\nvar mh = require('multihashes');\n\nvar last = require('it-last');\n\nvar addLink = /*#__PURE__*/function () {\n  var _ref = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(context, options) {\n    var meta;\n    return _regeneratorRuntime.wrap(function _callee$(_context) {\n      while (1) {\n        switch (_context.prev = _context.next) {\n          case 0:\n            if (!(!options.parentCid && !options.parent)) {\n              _context.next = 2;\n              break;\n            }\n\n            throw errCode(new Error('No parent node or CID passed to addLink'), 'EINVALIDPARENT');\n\n          case 2:\n            if (!(options.parentCid && !CID.isCID(options.parentCid))) {\n              _context.next = 4;\n              break;\n            }\n\n            throw errCode(new Error('Invalid CID passed to addLink'), 'EINVALIDPARENTCID');\n\n          case 4:\n            if (options.parent) {\n              _context.next = 9;\n              break;\n            }\n\n            log(\"Loading parent node \".concat(options.parentCid));\n            _context.next = 8;\n            return context.ipld.get(options.parentCid);\n\n          case 8:\n            options.parent = _context.sent;\n\n          case 9:\n            if (options.cid) {\n              _context.next = 11;\n              break;\n            }\n\n            throw errCode(new Error('No child cid passed to addLink'), 'EINVALIDCHILDCID');\n\n          case 11:\n            if (options.name) {\n              _context.next = 13;\n              break;\n            }\n\n            throw errCode(new Error('No child name passed to addLink'), 'EINVALIDCHILDNAME');\n\n          case 13:\n            if (!CID.isCID(options.cid)) {\n              options.cid = new CID(options.cid);\n            }\n\n            if (!(!options.size && options.size !== 0)) {\n              _context.next = 16;\n              break;\n            }\n\n            throw errCode(new Error('No child size passed to addLink'), 'EINVALIDCHILDSIZE');\n\n          case 16:\n            meta = UnixFS.unmarshal(options.parent.Data);\n\n            if (!(meta.type === 'hamt-sharded-directory')) {\n              _context.next = 20;\n              break;\n            }\n\n            log('Adding link to sharded directory');\n            return _context.abrupt(\"return\", addToShardedDirectory(context, options));\n\n          case 20:\n            if (!(options.parent.Links.length >= options.shardSplitThreshold)) {\n              _context.next = 23;\n              break;\n            }\n\n            log('Converting directory to sharded directory');\n            return _context.abrupt(\"return\", convertToShardedDirectory(context, _objectSpread(_objectSpread({}, options), {}, {\n              mtime: meta.mtime,\n              mode: meta.mode\n            })));\n\n          case 23:\n            log(\"Adding \".concat(options.name, \" (\").concat(options.cid, \") to regular directory\"));\n            return _context.abrupt(\"return\", addToDirectory(context, options));\n\n          case 25:\n          case \"end\":\n            return _context.stop();\n        }\n      }\n    }, _callee);\n  }));\n\n  return function addLink(_x, _x2) {\n    return _ref.apply(this, arguments);\n  };\n}();\n\nvar convertToShardedDirectory = /*#__PURE__*/function () {\n  var _ref2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2(context, options) {\n    var result;\n    return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n      while (1) {\n        switch (_context2.prev = _context2.next) {\n          case 0:\n            _context2.next = 2;\n            return createShard(context, options.parent.Links.map(function (link) {\n              return {\n                name: link.Name,\n                size: link.Tsize,\n                cid: link.Hash\n              };\n            }).concat({\n              name: options.name,\n              size: options.size,\n              cid: options.cid\n            }), options);\n\n          case 2:\n            result = _context2.sent;\n            log(\"Converted directory to sharded directory \".concat(result.cid));\n            return _context2.abrupt(\"return\", result);\n\n          case 5:\n          case \"end\":\n            return _context2.stop();\n        }\n      }\n    }, _callee2);\n  }));\n\n  return function convertToShardedDirectory(_x3, _x4) {\n    return _ref2.apply(this, arguments);\n  };\n}();\n\nvar addToDirectory = /*#__PURE__*/function () {\n  var _ref3 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3(context, options) {\n    var node, hashAlg, cid;\n    return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n      while (1) {\n        switch (_context3.prev = _context3.next) {\n          case 0:\n            options.parent.rmLink(options.name);\n            options.parent.addLink(new DAGLink(options.name, options.size, options.cid));\n            node = UnixFS.unmarshal(options.parent.Data);\n\n            if (node.mtime) {\n              // Update mtime if previously set\n              node.mtime = new Date();\n              options.parent = new DAGNode(node.marshal(), options.parent.Links);\n            }\n\n            hashAlg = mh.names[options.hashAlg]; // Persist the new parent DAGNode\n\n            _context3.next = 7;\n            return context.ipld.put(options.parent, mc.DAG_PB, {\n              cidVersion: options.cidVersion,\n              hashAlg: hashAlg,\n              onlyHash: !options.flush\n            });\n\n          case 7:\n            cid = _context3.sent;\n            return _context3.abrupt(\"return\", {\n              node: options.parent,\n              cid: cid,\n              size: options.parent.size\n            });\n\n          case 9:\n          case \"end\":\n            return _context3.stop();\n        }\n      }\n    }, _callee3);\n  }));\n\n  return function addToDirectory(_x5, _x6) {\n    return _ref3.apply(this, arguments);\n  };\n}();\n\nvar addToShardedDirectory = /*#__PURE__*/function () {\n  var _ref4 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee4(context, options) {\n    var _yield$addFileToShard, shard, path, result, node, oldLink, newLink;\n\n    return _regeneratorRuntime.wrap(function _callee4$(_context4) {\n      while (1) {\n        switch (_context4.prev = _context4.next) {\n          case 0:\n            _context4.next = 2;\n            return addFileToShardedDirectory(context, options);\n\n          case 2:\n            _yield$addFileToShard = _context4.sent;\n            shard = _yield$addFileToShard.shard;\n            path = _yield$addFileToShard.path;\n            _context4.next = 7;\n            return last(shard.flush('', context.block));\n\n          case 7:\n            result = _context4.sent;\n            _context4.next = 10;\n            return context.ipld.get(result.cid);\n\n          case 10:\n            node = _context4.sent;\n            // we have written out the shard, but only one sub-shard will have been written so replace it in the original shard\n            oldLink = options.parent.Links.find(function (link) {\n              return link.Name.substring(0, 2) === path[0].prefix;\n            });\n            newLink = node.Links.find(function (link) {\n              return link.Name.substring(0, 2) === path[0].prefix;\n            });\n\n            if (oldLink) {\n              options.parent.rmLink(oldLink.Name);\n            }\n\n            options.parent.addLink(newLink);\n            return _context4.abrupt(\"return\", updateHamtDirectory(context, options.parent.Links, path[0].bucket, options));\n\n          case 16:\n          case \"end\":\n            return _context4.stop();\n        }\n      }\n    }, _callee4);\n  }));\n\n  return function addToShardedDirectory(_x7, _x8) {\n    return _ref4.apply(this, arguments);\n  };\n}();\n\nvar addFileToShardedDirectory = /*#__PURE__*/function () {\n  var _ref5 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee5(context, options) {\n    var file, rootBucket, node, shard, position, path, index, _loop, _ret;\n\n    return _regeneratorRuntime.wrap(function _callee5$(_context6) {\n      while (1) {\n        switch (_context6.prev = _context6.next) {\n          case 0:\n            file = {\n              name: options.name,\n              cid: options.cid,\n              size: options.size\n            }; // start at the root bucket and descend, loading nodes as we go\n\n            _context6.next = 3;\n            return recreateHamtLevel(options.parent.Links);\n\n          case 3:\n            rootBucket = _context6.sent;\n            node = UnixFS.unmarshal(options.parent.Data);\n            shard = new DirSharded({\n              root: true,\n              dir: true,\n              parent: null,\n              parentKey: null,\n              path: '',\n              dirty: true,\n              flat: false,\n              mode: node.mode\n            }, options);\n            shard._bucket = rootBucket;\n\n            if (node.mtime) {\n              // update mtime if previously set\n              shard.mtime = new Date();\n            } // load subshards until the bucket & position no longer changes\n\n\n            _context6.next = 10;\n            return rootBucket._findNewBucketAndPos(file.name);\n\n          case 10:\n            position = _context6.sent;\n            path = toBucketPath(position);\n            path[0].node = options.parent;\n            index = 0;\n            _loop = /*#__PURE__*/_regeneratorRuntime.mark(function _loop() {\n              var segment, node, link, subShard, _position, nextSegment;\n\n              return _regeneratorRuntime.wrap(function _loop$(_context5) {\n                while (1) {\n                  switch (_context5.prev = _context5.next) {\n                    case 0:\n                      segment = path[index];\n                      index++;\n                      node = segment.node;\n                      link = node.Links.find(function (link) {\n                        return link.Name.substring(0, 2) === segment.prefix;\n                      });\n\n                      if (link) {\n                        _context5.next = 8;\n                        break;\n                      }\n\n                      // prefix is new, file will be added to the current bucket\n                      log(\"Link \".concat(segment.prefix).concat(file.name, \" will be added\"));\n                      index = path.length;\n                      return _context5.abrupt(\"return\", \"break\");\n\n                    case 8:\n                      if (!(link.Name === \"\".concat(segment.prefix).concat(file.name))) {\n                        _context5.next = 12;\n                        break;\n                      }\n\n                      // file already existed, file will be added to the current bucket\n                      log(\"Link \".concat(segment.prefix).concat(file.name, \" will be replaced\"));\n                      index = path.length;\n                      return _context5.abrupt(\"return\", \"break\");\n\n                    case 12:\n                      if (!(link.Name.length > 2)) {\n                        _context5.next = 16;\n                        break;\n                      }\n\n                      // another file had the same prefix, will be replaced with a subshard\n                      log(\"Link \".concat(link.Name, \" \").concat(link.Hash, \" will be replaced with a subshard\"));\n                      index = path.length;\n                      return _context5.abrupt(\"return\", \"break\");\n\n                    case 16:\n                      // load sub-shard\n                      log(\"Found subshard \".concat(segment.prefix));\n                      _context5.next = 19;\n                      return context.ipld.get(link.Hash);\n\n                    case 19:\n                      subShard = _context5.sent;\n\n                      if (path[index]) {\n                        _context5.next = 29;\n                        break;\n                      }\n\n                      log(\"Loaded new subshard \".concat(segment.prefix));\n                      _context5.next = 24;\n                      return recreateHamtLevel(subShard.Links, rootBucket, segment.bucket, parseInt(segment.prefix, 16));\n\n                    case 24:\n                      _context5.next = 26;\n                      return rootBucket._findNewBucketAndPos(file.name);\n\n                    case 26:\n                      _position = _context5.sent;\n                      path.push({\n                        bucket: _position.bucket,\n                        prefix: toPrefix(_position.pos),\n                        node: subShard\n                      });\n                      return _context5.abrupt(\"return\", \"break\");\n\n                    case 29:\n                      nextSegment = path[index]; // add next levels worth of links to bucket\n\n                      _context5.next = 32;\n                      return addLinksToHamtBucket(subShard.Links, nextSegment.bucket, rootBucket);\n\n                    case 32:\n                      nextSegment.node = subShard;\n\n                    case 33:\n                    case \"end\":\n                      return _context5.stop();\n                  }\n                }\n              }, _loop);\n            });\n\n          case 15:\n            if (!(index < path.length)) {\n              _context6.next = 22;\n              break;\n            }\n\n            return _context6.delegateYield(_loop(), \"t0\", 17);\n\n          case 17:\n            _ret = _context6.t0;\n\n            if (!(_ret === \"break\")) {\n              _context6.next = 20;\n              break;\n            }\n\n            return _context6.abrupt(\"break\", 22);\n\n          case 20:\n            _context6.next = 15;\n            break;\n\n          case 22:\n            _context6.next = 24;\n            return shard._bucket.put(file.name, {\n              size: file.size,\n              cid: file.cid\n            });\n\n          case 24:\n            return _context6.abrupt(\"return\", {\n              shard: shard,\n              path: path\n            });\n\n          case 25:\n          case \"end\":\n            return _context6.stop();\n        }\n      }\n    }, _callee5);\n  }));\n\n  return function addFileToShardedDirectory(_x9, _x10) {\n    return _ref5.apply(this, arguments);\n  };\n}();\n\nvar toBucketPath = function toBucketPath(position) {\n  var bucket = position.bucket;\n  var positionInBucket = position.pos;\n  var path = [{\n    bucket: bucket,\n    prefix: toPrefix(positionInBucket)\n  }];\n  bucket = position.bucket._parent;\n  positionInBucket = position.bucket._posAtParent;\n\n  while (bucket) {\n    path.push({\n      bucket: bucket,\n      prefix: toPrefix(positionInBucket)\n    });\n    positionInBucket = bucket._posAtParent;\n    bucket = bucket._parent;\n  }\n\n  path.reverse();\n  return path;\n};\n\nmodule.exports = addLink;","map":null,"metadata":{},"sourceType":"script"}